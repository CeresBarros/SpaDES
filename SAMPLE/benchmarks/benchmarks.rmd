---
title: "Benchmarking with R/SpaDES"
author: "Eliot McIntire"
date: "Friday, Octore 6, 2014"
output: html_document
---

The objective of this file is to show some speed comparisons between R and C++ and in some cases, other languages or software.

## Low level functionality

We will begin with low level functions that are generally highly optimized in R. As a result, the comparison C++ functions, which are not optimized, may not fully represent what C++ could do. However, this represents a real world issue: if the "out of the box" R function is competitive with a "quick" C++ version, then the R version is easier to write as there is no further development. If there is a desire or need for more speed, then a more optimzed C++ version can be written and used either in native C++ applications or R.


```{r load_cpp_functions, cache=FALSE, eval=TRUE, echo=FALSE, }
library(data.table)
library(microbenchmark)
library(Rcpp)
library(microbenchmark)
path <- "~/GitHub/SpaDES/SAMPLE/Functions in progress/"
setwd(path)
sourceCpp(file="meanCPP.cpp")
```

For the mean, I show two different C++ versiopns. The R function, "mean" is somewhat slower (1/2x), but the .Primitive option in R, sum/length is faster than either C++ function.
```{r mean, eval=TRUE, cache=FALSE, echo=FALSE, cache=TRUE}
#library(Rcpp)
library(microbenchmark)
#sourceCpp(file="meanCPP.cpp")
x <- runif(1e5)

x1 = matrix(x, ncol=1)
microbenchmark(a<-meanC1(x), d<-meanC2(x), b<-mean(x), e<-mean.default(x), g<-sum(x)/length(x), i<- .Internal(mean(x)), h<-rowMeans(x1))
all.equal(a,b, d, e, g, h, i)
```


Below, we take the minimum of each of a pair of columns.  
```{r pmin, eval=TRUE, cache=TRUE}
x2 <- rnorm(1e5)
rm(a, b, d)
(mb<-microbenchmark(a<-pminC(x,x2),b<-base::pmin(x,x2), d<-.Internal(pmin(x,x2))))
print(pmins<-round(summary(mb)[[4]][1]/min(summary(mb)[[4]][3])),0)
all.equal(a,b,d)
```

The internal R function is ***`r round(pmins)`x*** faster than the C++ version, or the base R version.

This is taken from a blog post by Wingfeet at http://www.r-bloggers.com/quicksort-speed-just-in-time-compiling-and-vectorizing/ which drew on benchmark tests here: http://julialang.org/ 
Essentially, this was a benchmark to test the speed of Julia. It shows for the Quicksort, that R is 524x slower than C.  Below is a "simple" version, then the best, fastest version that Wingfeet was able to do. But, there was no explicit comparison of how the base R sort would match with C. 

```{r sorting_fns, eval=TRUE, echo=FALSE, cache=TRUE}
qsort = function(a) {
    qsort_kernel = function(lo, hi) {
        i = lo
        j = hi
        while (i < hi) {
            pivot = a[floor((lo+hi)/2)]
            while (i <= j) {
                while (a[i] < pivot) i = i + 1
                while (a[j] > pivot) j = j - 1
                if (i <= j) {
                    t = a[i]
                    a[i] <<- a[j]
                    a[j] <<- t
                    i = i + 1;
                    j = j - 1;
                }
            }
            if (lo < j) qsort_kernel(lo, j)
            lo = i
            j = hi
        }
    }
    qsort_kernel(1, length(a))
    return(a)
}

wfqs1 <- function(x) {
  if (length(x)<2) return(x)
  pivot <- x[sample(length(x),1)]
  c(wfqs1(x[x<pivot]),x[x==pivot],wfqs1(x[x>pivot]))
}

wfqsx = function(a) {
  qsort_kernel = function(lo, hi) {
    if(lo>=hi) return()
    if(hi-lo==1) {
      if(a[lo]>a[hi]) {
        t <- a[lo]
        a[lo] <<- a[hi]
        a[hi] <<- t
      }
      return()
    }
    goUp <- a[(lo+1):hi]>a[lo]
    up <- which(goUp)
    do <- which(!goUp)
    pivottarget <- lo+length(do)
    up <- up[up<=length(do)]+lo
    do <- do[do>length(do)]+lo
    t <- a[do]
    a[do] <<- a[up]
    a[up] <<- t
    t <- a[pivottarget]
    a[pivottarget] <<- a[lo]
    a[lo] <<- t  
    qsort_kernel(lo,pivottarget-1)
    qsort_kernel(pivottarget+1, hi)
  }
  qsort_kernel(1, length(a))
  return(a)
}
```

```{r sorting, eval=TRUE, echo=TRUE, cache=TRUE}
#require(compiler)
#enableJIT(0)
x = runif(1e5)
(mb <- microbenchmark(a0 <- qsort(x), a <- wfqsx(x), b <- wfqs1(x), 
                      d <- sort(x), 
                      e <- sort(x, method="quick"),
                      f <- .Internal(sort(x,decreasing = FALSE)),
                      g <- data.table(x=x,key="x"),
                      times=2L))
print(sumReals<-round(summary(mb)[[4]][1]/min(summary(mb)[[4]][4:7])),0)
all.equal(a0,a,b,d,e,f,g$x)

# Integers
x = sample(1e5)
(mb <- microbenchmark(a0 <- qsort(x), a <- wfqsx(x), b <- wfqs1(x),
                      d <- sort(x), 
                      e <- sort(x, method="quick"), 
                      f <- .Internal(sort(x,decreasing = FALSE)),
                      g <- data.table(x=x,key="x"),
                      times=2L))
print(sumInts <- round(summary(mb)[[4]][1]/min(summary(mb)[[4]][4:7])),0)
all.equal(a0,a,b,d,e,f,g$x)

```

The first three function are 3 different implementations of the quicksort algorithm shown on the Julia pages, with the first, qsort, being the one that the Julia testers used. Using the data.table sorting we were able to achieve ***483x*** speedup if Reals, and **`r sumInts`x** speedup if integers. These put them as fast or faster than C or Fortran or Julia. In Wingfeet's blog post, he also showed that using JIT can speed up non-optimized, "procedural" R code, though not as fast as the low level functions that exist in various R packages.


Again, the fastest native R function is faster than a simple (unoptimized) C or C++ function. As with any language, there is faster code and slower code. With R, it may take a few tries, but there is usually a very fast option.

#### Conclusions
Clearly, low level speed can be achieved within R, often better than quick implementations in C or C++. This is because efforts have been made in primitives and internal functions with core R functions to provide optimal versions, without any extra user coding.  Many work flows to not require explicit loops. R's vectorization model allows for fast code, with little coding. ***Write vectorized code in R***

## High level functionality

R also has numerous high level functions and packages that allow users to do a diversity of analyses and data manipulations, from GIS to MCMC to optimally stored file-based object storing for fast access (ff package), and much more.  Here are a few examples.

### GIS

