<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Eliot J. B. McIntire" />


<title>Benchmarking R for SpaDES</title>

<script src="benchmarks_files/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link href="benchmarks_files/bootstrap-2.3.2/css/bootstrap.min.css" rel="stylesheet" />
<link href="benchmarks_files/bootstrap-2.3.2/css/bootstrap-responsive.min.css" rel="stylesheet" />
<script src="benchmarks_files/bootstrap-2.3.2/js/bootstrap.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="benchmarks_files/highlight/default.css"
      type="text/css" />
<script src="benchmarks_files/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="container-fluid main-container">


<div id="header">
<h1 class="title">Benchmarking R for <code>SpaDES</code></h1>
<h4 class="author"><em>Eliot J. B. McIntire</em></h4>
</div>

<div id="TOC">
<ul>
<li><a href="#low-level-functionality">Low level functionality</a><ul>
<li><a href="#high-level-functionality">High level functionality</a></li>
</ul></li>
<li><a href="#raster-to-polygon">Raster to Polygon</a></li>
<li><a href="#links-to-other-benchmark-testing-with-r">Links to other benchmark testing with R</a></li>
</ul>
</div>

<p>The objective of this file is to show some speed comparisons between R and C++ and in some cases, other languages or software. Clearly this is NOT a comparison between R and C++ because many of the functions in R are written in C++ and wrapped in R. This document shows three important points:</p>
<ol style="list-style-type: decimal">
<li><p>built-in R functions (written in R or C++ or any other language) are often faster than ad hoc C++ functions because they are optimized.</p></li>
<li><p>built-in R functions are to be used in a vectorized way, avoiding loops unless it is strictly necessary to keep the sequence</p></li>
<li><p>there are often different ways to do the same thing in R; some are much faster than others</p></li>
</ol>
<p>Tests are done on an HP Z400, Xeon 3.33 GHz processor, running Windows 7 Enterprise</p>
<div id="low-level-functionality" class="section level2">
<h2>Low level functionality</h2>
<p>We will begin with low level functions that are generally highly optimized in R. As a result, the comparison C++ functions, which are not optimized, may not fully represent what C++ could do. However, this represents a real world issue: if the “out of the box” R function is competitive with a “quick” C++ version, then the R version is easier to write as there is no further development. If there is a desire or need for more speed, then a more optimzed C++ version can be written and used either in native C++ applications or R.</p>
<pre class="r"><code>library(data.table)
library(microbenchmark)
library(Rcpp)
library(numbers)
library(magrittr) # for pipe used below</code></pre>
<pre><code>## 
## Attaching package: &#39;magrittr&#39;
## 
## The following object is masked from &#39;package:numbers&#39;:
## 
##     mod</code></pre>
<pre class="r"><code>library(dplyr)</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;
## 
## The following objects are masked from &#39;package:data.table&#39;:
## 
##     between, last
## 
## The following object is masked from &#39;package:stats&#39;:
## 
##     filter
## 
## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>#path &lt;- &quot;~/GitHub/SpaDES/SAMPLE/benchmarks&quot;
#path &lt;- system.file(&quot;vignettes&quot;, package=&quot;SpaDES&quot;)
#setwd(path)
#sourceCpp(file=&quot;meanCPP.cpp&quot;)</code></pre>
<pre class="r"><code>#include &lt;Rcpp.h&gt;
#using namespace Rcpp;

#// [[Rcpp::export]]
cppFunction(&#39;double meanC1(NumericVector x) {
  int n = x.size();
  double total = 0;

  for(int i = 0; i &lt; n; ++i) {
    total += x[i];
  }
  return total / n;
}&#39;)

cppFunction(&#39;double meanC2(NumericVector x) {
  int n = x.size();
  double y = 0;

  for(int i = 0; i &lt; n; ++i) {
    y += x[i] / n;
  }
  return y;
}&#39;)


cppFunction(&#39;NumericVector f2(NumericVector x) {
  int n = x.size();
  NumericVector out(n);

  out[0] = x[0];
  for(int i = 1; i &lt; n; ++i) {
    out[i] = out[i - 1] + x[i];
  }
  return out;
}&#39;)

cppFunction(&#39;bool f3(LogicalVector x) {
  int n = x.size();

  for(int i = 0; i &lt; n; ++i) {
    if (x[i]) return true;
  }
  return false;
}&#39;)

cppFunction(&#39;int f4(Function pred, List x) {
  int n = x.size();

  for(int i = 0; i &lt; n; ++i) {
    LogicalVector res = pred(x[i]);
    if (res[0]) return i + 1;
  }
  return 0;
}&#39;)

cppFunction(&#39;NumericVector pminC(NumericVector x, NumericVector y) {
  int n = std::max(x.size(), y.size());
  NumericVector x1 = rep_len(x, n);
  NumericVector y1 = rep_len(y, n);

  NumericVector out(n);

  for (int i = 0; i &lt; n; ++i) {
    out[i] = std::min(x1[i], y1[i]);
  }

  return out;
}&#39;)

cppFunction(&#39;int fibonacciC(const int x) {
    if (x == 0 || x == 1) return(x);
    return (fibonacciC(x - 1)) + fibonacciC(x - 2);
}&#39;)

cppFunction(&#39;int fibC(int n) {
    return n &lt; 2 ? n : fibC(n-1) + fibC(n-2);
}&#39;)</code></pre>
<p>For the mean, I show two different C++ versiopns. The R function, “mean” is somewhat slower (1/2x), but the .Primitive option in R, sum/length is faster than either C++ function.</p>
<div id="mean" class="section level4">
<h4>Mean</h4>
<pre><code>## Unit: microseconds
##                     expr     min      lq    mean  median      uq     max
##           a &lt;- meanC1(x)   92.47   94.92  112.20   96.61  101.07  1177.5
##           d &lt;- meanC2(x)  663.23  665.38  675.96  669.68  675.21   771.7
##             b &lt;- mean(x)  195.07  197.37  211.37  202.75  220.57   281.1
##     e &lt;- mean.default(x)  183.40  185.24  189.55  187.08  189.85   234.4
##    g &lt;- sum(x)/length(x)   91.85   93.08   97.05   94.16   96.77   144.1
##  i &lt;- .Internal(mean(x))  181.25  181.86  185.93  182.78  184.78   259.0
##        h &lt;- rowMeans(x1) 1114.50 1236.61 2422.86 1307.42 1506.94 44526.0
##  neval cld
##    100  a 
##    100  a 
##    100  a 
##    100  a 
##    100  a 
##    100  a 
##    100   b</code></pre>
<pre><code>## [1] TRUE</code></pre>
</div>
<div id="minimum-of-pair-of-numbers" class="section level4">
<h4>Minimum of pair of numbers</h4>
<p>Below, we take the minimum of each of a pair of columns.</p>
<pre class="r"><code>x2 &lt;- rnorm(1e5)
rm(a, b, d)
(mb&lt;-microbenchmark(a&lt;-pminC(x,x2),b&lt;-base::pmin(x,x2), d&lt;-.Internal(pmin(x,x2))))</code></pre>
<pre><code>## Unit: nanoseconds
##                         expr     min      lq    mean  median      uq
##            a &lt;- pminC(x, x2) 1251512 1313105 3436669 2200591 2643873
##       b &lt;- base::pmin(x, x2) 2934633 2975029 4606783 3012353 3092992
##  d &lt;- .Internal(pmin(x, x2))       0     307    1508    1536    2304
##       max neval cld
##  51439469   100   b
##  52134037   100   b
##      5222   100  a</code></pre>
<pre class="r"><code>print(pmins&lt;-round(summary(mb)[[4]][1]/min(summary(mb)[[4]][3]),0))</code></pre>
<pre><code>## [1] 2278</code></pre>
<pre class="r"><code>all.equal(a,b,d)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>The internal R function is <strong><em>2278x</em></strong> faster than the C++ version, or the base R version.</p>
<p>This is taken from a blog post by Wingfeet at <a href="http://www.r-bloggers.com/quicksort-speed-just-in-time-compiling-and-vectorizing/" class="uri">http://www.r-bloggers.com/quicksort-speed-just-in-time-compiling-and-vectorizing/</a> which drew on benchmark tests here: <a href="http://julialang.org/" class="uri">http://julialang.org/</a> Essentially, this was a benchmark to test the speed of Julia. It shows for the Quicksort, that R is 524x slower than C. Below is a “simple” version, then the best, fastest version that Wingfeet was able to do. But, there was no explicit comparison of how the base R sort would match with C.</p>
</div>
<div id="sorting" class="section level4">
<h4>Sorting</h4>
<p>Real number sorting:</p>
<pre class="r"><code>x = runif(1e5)
xtbl &lt;- tbl_df(data.frame(x=x))
(mb &lt;- microbenchmark(a0 &lt;- qsort(x), a &lt;- wfqsx(x), b &lt;- wfqs1(x), 
                      d &lt;- sort(x), 
                      e &lt;- sort(x, method=&quot;quick&quot;),
                      f &lt;- .Internal(sort(x,decreasing = FALSE)),
                      g &lt;- data.table(x=x,key=&quot;x&quot;), h&lt;-arrange(xtbl,x),
                      times=1L))</code></pre>
<pre><code>## Unit: milliseconds
##                                         expr      min       lq     mean
##                               a0 &lt;- qsort(x) 3365.289 3365.289 3365.289
##                                a &lt;- wfqsx(x) 1228.756 1228.756 1228.756
##                                b &lt;- wfqs1(x) 1017.220 1017.220 1017.220
##                                 d &lt;- sort(x)   11.735   11.735   11.735
##               e &lt;- sort(x, method = &quot;quick&quot;)    8.420    8.420    8.420
##  f &lt;- .Internal(sort(x, decreasing = FALSE))   12.354   12.354   12.354
##            g &lt;- data.table(x = x, key = &quot;x&quot;)    8.302    8.302    8.302
##                        h &lt;- arrange(xtbl, x)  158.670  158.670  158.670
##    median       uq      max neval
##  3365.289 3365.289 3365.289     1
##  1228.756 1228.756 1228.756     1
##  1017.220 1017.220 1017.220     1
##    11.735   11.735   11.735     1
##     8.420    8.420    8.420     1
##    12.354   12.354   12.354     1
##     8.302    8.302    8.302     1
##   158.670  158.670  158.670     1</code></pre>
<pre class="r"><code>print(sumReals&lt;-round(summary(mb)[[4]][1]/min(summary(mb)[[4]][4:7]),0))</code></pre>
<pre><code>## [1] 405</code></pre>
<pre class="r"><code>all.equalV(a0,a,b,d,e,f,g$x,h$x)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>And Integers are faster in the low-level R functions:</p>
<pre class="r"><code>x = sample(1e6,size = 1e5)
xtbl &lt;- tbl_df(data.frame(x=x))
(mb &lt;- microbenchmark(a0 &lt;- qsort(x), a &lt;- wfqsx(x), b &lt;- wfqs1(x),
                      d &lt;- sort(x), 
                      e &lt;- sort(x, method=&quot;quick&quot;), 
                      f &lt;- .Internal(sort(x,decreasing = FALSE)),
                      g &lt;- data.table(x=x,key=&quot;x&quot;), h&lt;-arrange(xtbl,x),
                      times=1L))</code></pre>
<pre><code>## Unit: milliseconds
##                                         expr      min       lq     mean
##                               a0 &lt;- qsort(x) 3467.903 3467.903 3467.903
##                                a &lt;- wfqsx(x) 1121.635 1121.635 1121.635
##                                b &lt;- wfqs1(x)  957.288  957.288  957.288
##                                 d &lt;- sort(x)   10.896   10.896   10.896
##               e &lt;- sort(x, method = &quot;quick&quot;)    6.989    6.989    6.989
##  f &lt;- .Internal(sort(x, decreasing = FALSE))   10.133   10.133   10.133
##            g &lt;- data.table(x = x, key = &quot;x&quot;)    4.482    4.482    4.482
##                        h &lt;- arrange(xtbl, x)   27.899   27.899   27.899
##    median       uq      max neval
##  3467.903 3467.903 3467.903     1
##  1121.635 1121.635 1121.635     1
##   957.288  957.288  957.288     1
##    10.896   10.896   10.896     1
##     6.989    6.989    6.989     1
##    10.133   10.133   10.133     1
##     4.482    4.482    4.482     1
##    27.899   27.899   27.899     1</code></pre>
<pre class="r"><code>print(sumInts &lt;- round(summary(mb)[[4]][1]/min(summary(mb)[[4]][4:7]),0))</code></pre>
<pre><code>## [1] 774</code></pre>
<pre class="r"><code>all.equalV(a0,a,b,d,e,f,g$x,h$x)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>The first three function are 3 different implementations of the quicksort algorithm shown on the Julia pages, with the first, qsort, being the one that the Julia testers used. Using the data.table sorting we were able to achieve <strong><em>483x</em></strong> speedup if Reals, and <strong>774x</strong> speedup if integers. These put them as fast or faster than C or Fortran or Julia. In Wingfeet’s blog post, he also showed that using JIT can speed up non-optimized, “procedural” R code, though not as fast as the low level functions that exist in various R packages.</p>
</div>
<div id="fibonacci" class="section level4">
<h4>Fibonacci</h4>
<pre class="r"><code>fibR1 = function(n) {
    fib &lt;- numeric(n)
    fib[1:2] &lt;- c(1, 2)
    for (k in 3:n) {
        fib[k] &lt;- fib[k - 1] + fib[k - 2]
    } 
    return(fib)
}
fibR2 = function(n) {
     if (n &lt; 2) {
         return(n)
     } else {
         return(fibR2(n-1) + fibR2(n-2))
     }
}

N = 20L
(mbFib &lt;- microbenchmark(times=10L, a&lt;-numbers::fibonacci(N, sequence=TRUE)[N], 
                         b&lt;- fibC(N+1), d&lt;-fibonacciC(N+1), e&lt;-fibR1(N)[N], f&lt;-fibR2(N+1)))</code></pre>
<pre><code>## Unit: microseconds
##                                            expr      min       lq     mean
##  a &lt;- numbers::fibonacci(N, sequence = TRUE)[N]    81.71    83.86   117.23
##                                b &lt;- fibC(N + 1)    58.67    59.90    66.57
##                          d &lt;- fibonacciC(N + 1)    59.90    60.21    69.15
##                                e &lt;- fibR1(N)[N]    45.77    47.00    58.24
##                               f &lt;- fibR2(N + 1) 91803.03 92590.06 93576.25
##    median       uq      max neval cld
##    106.44   139.16   201.21    10  a 
##     62.82    70.35    94.92    10  a 
##     65.74    74.34    99.22    10  a 
##     49.15    68.50    90.93    10  a 
##  92998.17 94501.73 97267.41    10   b</code></pre>
<pre class="r"><code>all.equalV(a,b,d, e, f)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>Here, one of the two native R implementations is <strong>1x faster</strong> by pre-allocating the output vector size. The fibonacci function in the package numbers was 2x slower than the faster RR function because it has error checking. <strong><em>The native C++ version was 0.87x slower</em></strong>.</p>
</div>
<div id="loops" class="section level4">
<h4>Loops</h4>
<p>Loops have been the achilles heel of R in the past. In version 3.1 and forward, much of this appears to be gone. As could be seen in the fibonacci example, pre-allocating a vector and filling it up inside a loop can now be very fast and efficient in native R. To demonstrate these points, below are 6 ways to achieve the same result in R, beginning with a naive loop approach, and working up to the fully vectorized approach. I am using a very fast vectorized function, seq_len, to emphasize the differences between using loops and optimized vectorized functions.</p>
<pre class="r"><code>N = 2e4

(mb = microbenchmark(times=4L,
naiveVector &lt;- {
  set.seed(104)
  a &lt;- numeric()
    for (i in 1:N) {
      a[i] = runif(1)+1
    } 
   a
  } ,
presetVector1 &lt;- {
    set.seed(104)
    norms &lt;- runif(N)
    # pre-allocating vector length, generating normal random numbers once in each loop
    b &lt;- numeric(N) 
    for (i in 1:N) {
      b[i] = norms[i]+1
    }
    b
  },
presetVector2 &lt;- {
      set.seed(104)
      b &lt;- runif(N) 
      sapply(b,function(x) x)
      },
presetVector3 &lt;- {
      set.seed(104)
      # pipe operator means that no intermediate objects are created
      num &lt;- numeric(1)
      b &lt;- runif(N) %&gt;%
        sapply(.,function(x) x)
      },
vectorized1 &lt;- {
  # vectorized with intermediate object
    set.seed(104)
    norms &lt;- runif(N)
    d &lt;- norms
    d
  },
vectorized2 &lt;- {
  set.seed(104)
  # no intermediate object
  runif(N)
  }

))</code></pre>
<pre><code>## Unit: microseconds
##                                                                                                                                           expr
##                           naiveVector &lt;- {     set.seed(104)     a &lt;- numeric()     for (i in 1:N) {         a[i] = runif(1) + 1     }     a }
##  presetVector1 &lt;- {     set.seed(104)     norms &lt;- runif(N)     b &lt;- numeric(N)     for (i in 1:N) {         b[i] = norms[i] + 1     }     b }
##                                                          presetVector2 &lt;- {     set.seed(104)     b &lt;- runif(N)     sapply(b, function(x) x) }
##                                    presetVector3 &lt;- {     set.seed(104)     num &lt;- numeric(1)     b &lt;- runif(N) %&gt;% sapply(., function(x) x) }
##                                                                vectorized1 &lt;- {     set.seed(104)     norms &lt;- runif(N)     d &lt;- norms     d }
##                                                                                              vectorized2 &lt;- {     set.seed(104)     runif(N) }
##       min       lq     mean   median       uq      max neval  cld
##  539153.7 539700.8 544237.7 542854.1 548774.6 552088.7     4    d
##   30076.8  30275.3  31135.4  31066.0  31995.6  32332.9     4   c 
##   16356.0  17245.2  18230.3  18299.9  19215.5  19965.5     4  b  
##   16952.2  17206.4  18122.5  17838.0  19038.6  19861.7     4  b  
##     716.4    736.2    754.0    762.5    771.8    774.7     4 a   
##     757.2    759.2    783.1    766.5    807.0    842.3     4 a</code></pre>
<pre class="r"><code>all.equalV(naiveVector, presetVector1, presetVector2, presetVector3, vectorized1, vectorized2)</code></pre>
<pre><code>## Warning: coercing argument of type &#39;character&#39; to logical</code></pre>
<pre><code>## [1] NA</code></pre>
<pre class="r"><code>print(sumLoops &lt;- round(summary(mb)[[4]][1]/summary(mb)[[4]][length(summary(mb)[[4]])],0))</code></pre>
<pre><code>## [1] 695</code></pre>
<p>The fully vectorized function is <strong><em>695x</em></strong> faster than the fully naive loop. Note also that making as few intermediate objects as possible is faster as well. Comparing vectorized1 and vectorized2 shows an improvement of 99%. <strong>Preallocating a vector</strong> improved by <strong><em>17x</em></strong>. Using pipes instead of inter</p>
</div>
<div id="conclusions" class="section level4">
<h4>Conclusions</h4>
<p>In all cases shown here, the fastest native R function is faster than a simple (unoptimized) C or C++ function. As with any language, there is faster code and slower code. With R, it may take a few tries, but there is usually a very fast option.</p>
<p>Clearly, low level speed can be achieved within R, often better than quick implementations in C or C++. This is because efforts have been made in primitives and internal functions with core R functions to provide optimal versions, without any extra user coding. Many work flows to not require explicit loops. R’s vectorization model allows for fast code, with little coding. <strong><em>Write vectorized code in R</em></strong></p>
</div>
<div id="high-level-functionality" class="section level3">
<h3>High level functionality</h3>
<p>R also has numerous high level functions and packages that allow users to do a diversity of analyses and data manipulations, from GIS to MCMC to optimally stored file-based object storing for fast access (ff package), and much more. Here are a few examples.</p>
<div id="gis" class="section level4">
<h4>GIS</h4>
<pre class="r"><code>  library(raster)  </code></pre>
<pre><code>## Loading required package: sp
## 
## Attaching package: &#39;raster&#39;
## 
## The following object is masked from &#39;package:dplyr&#39;:
## 
##     select
## 
## The following object is masked from &#39;package:magrittr&#39;:
## 
##     extract</code></pre>
<pre class="r"><code>  lcc05 &lt;- raster(&quot;c:/shared/data/LCC2005_V1_4a.tif&quot;)</code></pre>
<pre><code>## rgdal: version: 0.9-1, (SVN revision 518)
## Geospatial Data Abstraction Library extensions to R successfully loaded
## Loaded GDAL runtime: GDAL 1.11.0, released 2014/04/16
## Path to GDAL shared files: C:/Eliot/R/win-library/3.1/rgdal/gdal
## GDAL does not use iconv for recoding strings.
## Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
## Path to PROJ.4 shared files: C:/Eliot/R/win-library/3.1/rgdal/proj</code></pre>
<pre class="r"><code>  age &lt;- raster(&quot;c:/shared/data/age.tif&quot;)</code></pre>
<pre class="r"><code>ext1 &lt;- extent(-1073154,-987285,7438423,7512480) # small central Sask 100 Thousand
vegMapLcc1 &lt;- crop(lcc05,ext1)

ext2 &lt;- extent(1612240, 1895057, 6756615, 6907451) # small 600k pixels Quebec City Lac St. Jean
vegMapLcc2 &lt;- crop(lcc05,ext2)

ext3 &lt;- extent(-1380607, -345446, 7211410, 7971750) # large central BC 12Million
vegMapLcc3 &lt;- crop(lcc05,ext3)</code></pre>
<pre><code>## Loading required package: snow</code></pre>
<pre><code>## 12 cores detected</code></pre>
<pre><code>## Using cluster with 12 nodes
## Using cluster with 12 nodes
## Using cluster with 12 nodes</code></pre>
<pre><code>## Unit: seconds
##                                                                                 expr
##  vegMapLcc1.crsAge &lt;- projectRaster(vegMapLcc1, crs = crs(age),      method = &quot;ngb&quot;)
##  vegMapLcc2.crsAge &lt;- projectRaster(vegMapLcc2, crs = crs(age),      method = &quot;ngb&quot;)
##  vegMapLcc3.crsAge &lt;- projectRaster(vegMapLcc3, crs = crs(age),      method = &quot;ngb&quot;)
##     min     lq   mean median     uq    max neval
##   1.111  1.111  1.111  1.111  1.111  1.111     1
##   4.029  4.029  4.029  4.029  4.029  4.029     1
##  27.981 27.981 27.981 27.981 27.981 27.981     1</code></pre>
<pre><code>## Unit: milliseconds
##                                         expr   min    lq  mean median
##  age1.crsAge &lt;- crop(age, vegMapLcc1.crsAge) 131.6 131.6 131.6  131.6
##  age2.crsAge &lt;- crop(age, vegMapLcc2.crsAge) 218.6 218.6 218.6  218.6
##  age3.crsAge &lt;- crop(age, vegMapLcc3.crsAge) 413.6 413.6 413.6  413.6
##     uq   max neval
##  131.6 131.6     1
##  218.6 218.6     1
##  413.6 413.6     1</code></pre>
<pre><code>## 12 cores detected</code></pre>
<pre><code>## Warning: closing unused connection 16 (&lt;-W-VIC-A105200.nrn.nrcan.gc.ca:11993)
## Warning: closing unused connection 15 (&lt;-W-VIC-A105200.nrn.nrcan.gc.ca:11993)
## Warning: closing unused connection 14 (&lt;-W-VIC-A105200.nrn.nrcan.gc.ca:11993)
## Warning: closing unused connection 13 (&lt;-W-VIC-A105200.nrn.nrcan.gc.ca:11993)
## Warning: closing unused connection 12 (&lt;-W-VIC-A105200.nrn.nrcan.gc.ca:11993)
## Warning: closing unused connection 11 (&lt;-W-VIC-A105200.nrn.nrcan.gc.ca:11993)
## Warning: closing unused connection 10 (&lt;-W-VIC-A105200.nrn.nrcan.gc.ca:11993)
## Warning: closing unused connection 9 (&lt;-W-VIC-A105200.nrn.nrcan.gc.ca:11993)
## Warning: closing unused connection 8 (&lt;-W-VIC-A105200.nrn.nrcan.gc.ca:11993)
## Warning: closing unused connection 7 (&lt;-W-VIC-A105200.nrn.nrcan.gc.ca:11993)
## Warning: closing unused connection 6 (&lt;-W-VIC-A105200.nrn.nrcan.gc.ca:11993)
## Warning: closing unused connection 5 (&lt;-W-VIC-A105200.nrn.nrcan.gc.ca:11993)</code></pre>
<pre><code>## Using cluster with 12 nodes
## Using cluster with 12 nodes
## Using cluster with 12 nodes</code></pre>
<pre><code>## Unit: milliseconds
##                                                                        expr
##  ageMapSmall &lt;- projectRaster(age1.crsAge, to = vegMapLcc1, method = &quot;ngb&quot;)
##    ageMapMed &lt;- projectRaster(age2.crsAge, to = vegMapLcc2, method = &quot;ngb&quot;)
##     ageMapLg &lt;- projectRaster(age3.crsAge, to = vegMapLcc3, method = &quot;ngb&quot;)
##      min      lq    mean  median      uq     max neval
##    680.9   680.9   680.9   680.9   680.9   680.9     1
##   2107.0  2107.0  2107.0  2107.0  2107.0  2107.0     1
##  28018.2 28018.2 28018.2 28018.2 28018.2 28018.2     1</code></pre>
<p>Since the raster package can run in “parallel” mode for some of its functions, this reproject raster function reprojected <strong>12 million pixels</strong> in <strong><em>28 seconds</em></strong> on a 6 core, hyperthreaded machine (shows up as 12 cores), with a peak 600MB RAM use per core (7.2GB).</p>
</div>
</div>
</div>
<div id="raster-to-polygon" class="section level2">
<h2>Raster to Polygon</h2>
<p>The version of the function to polygonize a raster that exists in the raster package is slow. Thanks to John Baumgartner (<a href="http://johnbaumgartner.wordpress.com/2012/07/26/getting-rasters-into-shape-from-r/" class="uri">http://johnbaumgartner.wordpress.com/2012/07/26/getting-rasters-into-shape-from-r/</a> ), we can call a GDAL function, if we have python, GDAL core, and GDAL-python bindings installed. This speedup is on the order of 50x-100x, depending on what the output format is. In addition to the instructions on John’s web page, there are a few things that need to be done now. First, I used python3.3 because the GDAL python bindings for Windows only existed for 3.3. The current version of python is 3.4.2, so I used a slightly older version for this to work. And, there are 3 things to install, python, gdal core, and gdal python bindings (available on the gdal web page).</p>
<pre class="r"><code>(mbRasterToPoly &lt;- microbenchmark(times=1L,
ageMapPolypy &lt;- gdal_polygonizeR(ageMapSmall, outshape=file.path(&quot;c:&quot;,&quot;Temp&quot;,&quot;ageSmall&quot;)),
ageMapPolypyMed &lt;- gdal_polygonizeR(ageMapMed, outshape=file.path(&quot;c:&quot;,&quot;Temp&quot;,&quot;ageMed&quot;)),
ageMapPolypyLg &lt;- gdal_polygonizeR(ageMapLg, outshape=file.path(&quot;c:&quot;,&quot;Temp&quot;,&quot;ageLg&quot;))
))</code></pre>
<pre><code>## Unit: seconds
##                                                                                                expr
##  ageMapPolypy &lt;- gdal_polygonizeR(ageMapSmall, outshape = file.path(&quot;c:&quot;,      &quot;Temp&quot;, &quot;ageSmall&quot;))
##   ageMapPolypyMed &lt;- gdal_polygonizeR(ageMapMed, outshape = file.path(&quot;c:&quot;,      &quot;Temp&quot;, &quot;ageMed&quot;))
##      ageMapPolypyLg &lt;- gdal_polygonizeR(ageMapLg, outshape = file.path(&quot;c:&quot;,      &quot;Temp&quot;, &quot;ageLg&quot;))
##     min     lq   mean median     uq    max neval
##   16.76  16.76  16.76  16.76  16.76  16.76     1
##   14.81  14.81  14.81  14.81  14.81  14.81     1
##  175.59 175.59 175.59 175.59 175.59 175.59     1</code></pre>
<pre class="r"><code>(mbRasterToPoly &lt;- microbenchmark(times=1L,
  ageMapPoly &lt;- rasterToPolygons(ageMapSmall, dissolve=TRUE),
  ageMapPolyMed &lt;- rasterToPolygons(ageMapMed, dissolve=TRUE)
))</code></pre>
<pre><code>## Loading required package: rgeos
## rgeos version: 0.3-8, (SVN revision 460)
##  GEOS runtime version: 3.4.2-CAPI-1.8.2 r3921 
##  Polygon checking: TRUE</code></pre>
<pre><code>## Unit: seconds
##                                                           expr    min
##   ageMapPoly &lt;- rasterToPolygons(ageMapSmall, dissolve = TRUE)  47.37
##  ageMapPolyMed &lt;- rasterToPolygons(ageMapMed, dissolve = TRUE) 288.28
##      lq   mean median     uq    max neval
##   47.37  47.37  47.37  47.37  47.37     1
##  288.28 288.28 288.28 288.28 288.28     1</code></pre>
<pre class="r"><code>#endCluster()</code></pre>
</div>
<div id="links-to-other-benchmark-testing-with-r" class="section level2">
<h2>Links to other benchmark testing with R</h2>
<div id="comparing-data.table-dplyr-and-pandas-in-python" class="section level4">
<h4>Comparing data.table, dplyr, and pandas in Python:</h4>
<p><a href="https://github.com/Rdatatable/data.table/wiki/Benchmarks-%3A-Grouping">https://github.com/Rdatatable/data.table/wiki/Benchmarks-%3A-Grouping</a></p>
</div>
<div id="comparing-data.table-and-dplyr-for-split-combine-apply-style-analysis" class="section level4">
<h4>Comparing data.table and dplyr for split-combine-apply style analysis:</h4>
<p><a href="http://www.brodieg.com/?p=7" class="uri">http://www.brodieg.com/?p=7</a></p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
