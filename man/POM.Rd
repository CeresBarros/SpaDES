% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/POM.R
\docType{methods}
\name{POM}
\alias{POM}
\alias{POM,simList,character-method}
\title{Use Pattern Oriented Modeling to fit unknown parameters}
\usage{
POM(sim, params, objects, objFn, cl, optimizer = "DEoptim", sterr = FALSE,
  ..., objFnCompare = "MAD", optimControl = NULL)

\S4method{POM}{simList,character}(sim, params, objects, objFn, cl,
  optimizer = "DEoptim", sterr = FALSE, ..., objFnCompare = "MAD",
  optimControl = NULL)
}
\arguments{
\item{sim}{A \code{simList} simulation object, generally produced by \code{simInit}.}

\item{params}{Character vector of parameter names that can be changed by the optimizer. These
must be accessible with \code{params(sim)} internally.}

\item{objects}{A optional named list (must be specified if objFn is not).
The names of each list element must correspond to an object in the
\code{.GlobalEnv} and the list elements must be objects that can be accessed in
the ls(sim) internally. See details and examples.}

\item{objFn}{An optional objective function to be passed into \code{optimizer}.
If missing, then \code{POM} will use \code{objFnCompare} and
\code{objects} instead. If using \code{POM} with a SpaDES
simulation, this objFn must contain a spades call internally,
followed by a derivation of a value that can be minimized
but the \code{optimizer}. It must have, as first argument, the
values for the parameters. See example.}

\item{cl}{A cluster object. Optional. This would generally be created using
parallel::makeCluster or equivalent. This is an alternative way, instead
of beginCluster(), to use parallelism for this function, allowing for
more control over cluster use.}

\item{optimizer}{The function to use to optimize. Default is
"DEoptim". Currently it can also be "optim" or "rgenoud", which
use \code{stats::optim} or \code{rgenoud::genoud}, respectively.
The latter two do not seem optimal for stochastic problems and have
not been widely tested.}

\item{sterr}{Logical. If using \code{optimizer = "optim"}, the hessian can be calculated.
If this is TRUE, then the standard errors can be estimated using
that hessian, assuming normality.}

\item{...}{All objects needed in objFn}

\item{objFnCompare}{Character string. Either, "MAD" or "RMSE" indicating that inside the objective
function, data and prediction will be compared by Mean Absolute Deviation or
Root Mean Squared Error. Default is "MAD".}

\item{optimControl}{List of control arguments passed into the control of each
optimization routine. Currently, only passed to
\code{\link{DEoptim.control}} when \code{optimizer} is \code{"DEoptim"}}
}
\value{
A list with at least 2 elements. The first (or first several) will
be the returned object from the optimizer. The second (or last if there are
more than 2), named \code{args} is the set of arguments that were passed
into the control of the optimizer.
}
\description{
This is very much in alpha condition. It has been tested on simple problems,
as shown in the examples, with up to 2 parameters.
It appears that DEoptim is the superior package for the stochastic problems.
This should be used with caution as with all optimization routines. This function
can nevertheless take optim or genoud as optimizers, using
\code{stats::optim} or \code{rgenoud::genoud}, respectively. These latter
do not seem appropriate for stochastic problems however, and have not
been widely tested.
}
\details{
There are two ways to use this function, via 1) \code{objFn} or 2) \code{objects}.
1) The user can pass the entire
objective function to the \code{objFn} argument that will be passed directly
to the \code{optimizer}. For this, the user will likely need to pass named
objects as part of the \code{...}. 2) The slightly simpler approach is to pass a list of
'actual data--simulated data' pairs as a named list in \code{objects} and
specify how these objects should be compared via \code{objFnCompare} (whose default is
Mean Absolute Deviation or "MAD"). Option 1 offers more control to the
user, but may require more knowledge. Option 1 should likely contain
a call to \code{simInit(copy(simList))} and \code{spades} internally.  See examples
that show simple examples of each type, option 1 and option 2. In both cases,
\code{params} is required to indicate which parameters can be varied in
order to achieve the fit.

Currently, option 1) only exists when optimizer is "DEoptim", the default.

The upper and lower limits for parameter values are taken from the
metadata in the module. Thus, if the module metadata does not define the
upper and lower limits, or these are very wide, then the optimization
may have troubles. Currently, there is no way to override these upper
and lower limits; the module metadata should be changed if there needs
to be different parameter limits for optimization.

\code{objects} is a named list of data--pattern pairs.
Each of these pairs will be assessed against one another using
the \code{objFnCompare}. if there is more than one data--pattern
pair, then they will simply be added together in the objective
function. This gives equal weight to each pair. Thus, if there is
more than one data--pattern pair,
the user may wish to standarize the pairs (say between 0 and 1) so that
they are all on or about the same scale. Alternatively, the user
may wish to weight them differently, in which case, their relative
scales can be adjusted.

There are many options that can be passed to \code{\link[DEoptim]{DEoptim}},
(the details of which are in the help), using \code{optimControl}. The defaults
sent from \code{POM} to \code{DEoptim} are: steptol = 3 (meaning it will start
assessing convergence after 3 iterations, \code{NP = 2 * length(params)}
(meaning the population size is 20 x the number of parameters) and itermax =
200 (meaning it won't go past 200 iterations). These and others may need to be adjusted to obtain good values. NOTE:
DEoptim does not provide a direct estimate of confidence intervals. Also,
convergence is unreliable, and often only occurs because \code{itermax} is reached. Even
when convergence is indicated, the estimates are not guaranteed to be global
optima. This is different than other optimizers that will normally indicate
if convergence was not achieved at termination of the optimization.
}
\examples{
\dontrun{
 set.seed(89462)
 library(parallel)
 mySim <- simInit(
   times = list(start = 0.0, end = 2.0, timeunit = "year"),
   params = list(
     .globals = list(stackName = "landscape", burnStats = "nPixelsBurned"),
     fireSpread = list(nFires = 5),
     randomLandscapes = list(nx = 300, ny = 300)
   ),
   modules = list("randomLandscapes", "fireSpread", "caribouMovement"),
   paths = list(modulePath = system.file("sampleModules", package = "SpaDES"))
 )

 # Since this is a made up example, we don't have real data
 #  to run POM against. Instead, we will run the model once,
 #  take the values at the end of the simulation as if they
 #  are real data, then rerun the POM function next,
 #  comparing these "data" with the simulated values
 #  using Mean Absolute Deviation
 outData <- spades(copy(mySim), .plotInitialTime = NA)

 # Extract the "true" data, in this case, the "proportion of cells burned"
 # Function defined that will use landscape$Fires map from simList,
 #  i.e., sim$landscape$Fires
 #  the return value being compared via MAD with propCellBurnedData
 propCellBurnedFn <- function(landscape) {
              sum(getValues(landscape$Fires))/ncell(landscape$Fires)
            }
 propCellBurnedData <- propCellBurnedFn(outData$landscape)
 # visualize the burned maps of true "data"
 clearPlot()
 Plot(outData$landscape$Fires)

# Example 1 - 1 parameter
 # In words, this says, "find the best value of spreadprob such that
 #  the proportion of the area burned in the simulation
 #  is as close as possible to the proportion area burned in
 #  the "data", using \\code{optim()}. In general, optim will
 #  not work well for stochastic models, but it works fine here
 #  because this is a simple problem

 # often not reliable for stochastic problems
 out <- POM(mySim, "spreadprob", optimizer = "optim",
            list(propCellBurnedData = propCellBurnedFn),
            hessian = TRUE) # using optim, can get Hessian

 # Try same fit using DEoptim, the default
 # can use cluster if computer is multi-threaded
 cl <- makeCluster(detectCores() - 1) # comment out if no cluster desired
 out1 <- POM(mySim, "spreadprob",
            list(propCellBurnedData = propCellBurnedFn), # data = pattern pair
            cl = cl) # comment out if no cluster

# Example 2 - 2 parameters
 # Function defined that will use caribou from sim$caribou, with
 #  the return value being compared via MAD with N1000
 # Here, divide by 1000 so the numbers are in the range of 0 to 1
 #  (because the possible range of values in the metadata for caribouMovement
 #  module, parameter N, is from 10 to 1000)
 caribouFn <- function(caribou) length(caribou)/1000

 # Extract "data" from simList object (normally, this would be actual data)
 N1000 <- caribouFn(outData$caribou)

 aTime <- Sys.time()
 out2 <- POM(mySim, c("spreadprob", "N"),
            list(propCellBurnedData = propCellBurnedFn,
                 N1000 = caribouFn),
            cl = cl)
 bTime <- Sys.time()
 # check that population overlaps known values (0.225 and 100)
 apply(out2$member$pop, 2, quantile, c(0.025, 0.975))

 print(paste("DEoptim", format(bTime - aTime)))
 #stopCluster(cl)

# Example 3 - using objFn instead of objects

 # list all the parameters in the simList, from these, we select to vary
 p(mySim)

 # Objective Function Example:
 #   objective function must have several elements
 #   - first argument must be parameter vector, passed to and used by DEoptim
 #   - likely needs to take sim object, likely needs a copy
 #      because of pass-by-reference semantics of sim objects
 #   - pass data that will be used internally for objective function
 objFnEx <- function(pars, # param values
                     sim, # simList object
                     N1000, propCellBurnedData, caribouFn, propCellBurnedFn) { # data

   # make a copy of simList because it will possibly be altered by spades call
   sim1 <- SpaDES::copy(sim)

   # take the parameters and assign them to simList
   params(sim1)$fireSpread$spreadprob <- pars[1]
   params(sim1)$caribouMovement$N <- pars[2]

   # run spades, without plotting
   out <- spades(sim1, .plotInitialTime = NA)

   # calculate outputs
   propCellBurnedOut <- propCellBurnedFn(out$landscape)
   N1000_Out <- caribouFn(out$caribou)

   minimizeFn <- abs(N1000_Out - N1000) +
                 abs(propCellBurnedOut - propCellBurnedData)

   # have more info reported to console, if desired
   # cat(minimizeFn)
   # cat(" ")
   # cat(pars)
   # cat("\\n")

   return(minimizeFn)
 }

 # Run DEoptim with custom objFn, identifying 2 parameters to allow
 #  to vary, and pass all necessary objects required for the
 #  objFn


 # choose 2 of them to vary. Need to identify them in params & inside objFn
 # Change optimization parameters to alter how convergence is achieved
 out5 <- POM(mySim, params = c("spreadprob", "N"),
             objFn = objFnEx,
             N1000 = N1000,
             propCellBurnedData = propCellBurnedData,
             caribouFn = caribouFn,
             propCellBurnedFn = propCellBurnedFn,
             cl = cl, # uncomment for cluster
             # see ?DEoptim.control for explanation of these options
             optimControl = list(
               NP = 100, # run 100 populations, allowing quantiles to be calculated
               initialpop = matrix(c(runif(100, 0.2, 0.24), runif(100, 80, 120)), ncol = 2)
             )
           )

# Can also use an optimizer directly -- miss automatic parameter bounds,
#  and automatic objective function using option 2
require(DEoptim)
out7 <- DEoptim(fn = objFnEx,
                sim = mySim,
                N1000 = N1000,
                propCellBurnedData = propCellBurnedData,
                caribouFn = caribouFn,
                propCellBurnedFn = propCellBurnedFn,
                cl = cl, # uncomment for cluster
                # see ?DEoptim.control for explanation of these options
                control = DEoptim.control(steptol = 3, parallelType = 3,
                                          initialpop = matrix(c(runif(40, 0.2, 0.24),
                                                                runif(40, 80, 120)),
                                                              ncol = 2)),
                lower = c(0.2, 80), upper = c(0.24, 120))

 }
}
\author{
Eliot McIntire
}
\seealso{
\code{\link{spades}}, \code{\link[parallel]{makeCluster}},
\code{\link{simInit}}
}

